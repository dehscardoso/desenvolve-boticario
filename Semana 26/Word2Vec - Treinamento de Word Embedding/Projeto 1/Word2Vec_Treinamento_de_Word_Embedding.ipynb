{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://images2.imgbox.com/32/ac/wucGkuem_o.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U -q spacy\n",
    "#%pip install -q gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bx8rtu0JZiMx"
   },
   "source": [
    "### Importando bibliotecas e criando dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "kmUZvse1UCVb",
    "outputId": "2e2aa1b8-a0d1-4f28-8244-046ea458d42a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "spacy.cli.download(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "artigo_treino = pd.read_csv(\"treino.csv\")\n",
    "artigo_teste = pd.read_csv(\"teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Após polêmica, Marine Le Pen diz que abomina n...</td>\n",
       "      <td>A candidata da direita nacionalista à Presidên...</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Macron e Le Pen vão ao 2º turno na França, em ...</td>\n",
       "      <td>O centrista independente Emmanuel Macron e a d...</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/04/187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apesar de larga vitória nas legislativas, Macr...</td>\n",
       "      <td>As eleições legislativas deste domingo (19) na...</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>mundo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mundo/2017/06/189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Governo antecipa balanço, e Alckmin anuncia qu...</td>\n",
       "      <td>O número de ocorrências de homicídios dolosos ...</td>\n",
       "      <td>2015-07-24</td>\n",
       "      <td>cotidiano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/cotidiano/2015/07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Após queda em maio, a atividade econômica sobe...</td>\n",
       "      <td>A economia cresceu 0,25% no segundo trimestre,...</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/08/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Após polêmica, Marine Le Pen diz que abomina n...   \n",
       "1  Macron e Le Pen vão ao 2º turno na França, em ...   \n",
       "2  Apesar de larga vitória nas legislativas, Macr...   \n",
       "3  Governo antecipa balanço, e Alckmin anuncia qu...   \n",
       "4  Após queda em maio, a atividade econômica sobe...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  A candidata da direita nacionalista à Presidên...  2017-04-28      mundo   \n",
       "1  O centrista independente Emmanuel Macron e a d...  2017-04-23      mundo   \n",
       "2  As eleições legislativas deste domingo (19) na...  2017-06-19      mundo   \n",
       "3  O número de ocorrências de homicídios dolosos ...  2015-07-24  cotidiano   \n",
       "4  A economia cresceu 0,25% no segundo trimestre,...  2017-08-17    mercado   \n",
       "\n",
       "  subcategory                                               link  \n",
       "0         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "1         NaN  http://www1.folha.uol.com.br/mundo/2017/04/187...  \n",
       "2         NaN  http://www1.folha.uol.com.br/mundo/2017/06/189...  \n",
       "3         NaN  http://www1.folha.uol.com.br/cotidiano/2015/07...  \n",
       "4         NaN  http://www1.folha.uol.com.br/mercado/2017/08/1...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artigo_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grandes irmãos</td>\n",
       "      <td>RIO DE JANEIRO - O Brasil, cada vez menos famí...</td>\n",
       "      <td>2017-03-06</td>\n",
       "      <td>colunas</td>\n",
       "      <td>ruycastro</td>\n",
       "      <td>http://www1.folha.uol.com.br/colunas/ruycastro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haddad congela orçamento e suspende emendas de...</td>\n",
       "      <td>O prefeito de São Paulo, Fernando Haddad (PT),...</td>\n",
       "      <td>2016-08-10</td>\n",
       "      <td>colunas</td>\n",
       "      <td>monicabergamo</td>\n",
       "      <td>http://www1.folha.uol.com.br/colunas/monicaber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Proposta de reforma da Fifa tem a divulgação d...</td>\n",
       "      <td>A Fifa divulgou, nesta quinta (10), um relatór...</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>esporte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/esporte/2015/09/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mercado incipiente, internet das coisas conect...</td>\n",
       "      <td>Bueiros, coleiras, aparelhos hospitalares, ele...</td>\n",
       "      <td>2016-11-09</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2016/09/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mortes: Psicanalista, estudou o autismo em cri...</td>\n",
       "      <td>Toda vez que o grupo de amigos de Silvana Rabe...</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>cotidiano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/cotidiano/2017/07...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                     Grandes irmãos   \n",
       "1  Haddad congela orçamento e suspende emendas de...   \n",
       "2  Proposta de reforma da Fifa tem a divulgação d...   \n",
       "3  Mercado incipiente, internet das coisas conect...   \n",
       "4  Mortes: Psicanalista, estudou o autismo em cri...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  RIO DE JANEIRO - O Brasil, cada vez menos famí...  2017-03-06    colunas   \n",
       "1  O prefeito de São Paulo, Fernando Haddad (PT),...  2016-08-10    colunas   \n",
       "2  A Fifa divulgou, nesta quinta (10), um relatór...  2015-10-09    esporte   \n",
       "3  Bueiros, coleiras, aparelhos hospitalares, ele...  2016-11-09    mercado   \n",
       "4  Toda vez que o grupo de amigos de Silvana Rabe...  2017-02-07  cotidiano   \n",
       "\n",
       "     subcategory                                               link  \n",
       "0      ruycastro  http://www1.folha.uol.com.br/colunas/ruycastro...  \n",
       "1  monicabergamo  http://www1.folha.uol.com.br/colunas/monicaber...  \n",
       "2            NaN  http://www1.folha.uol.com.br/esporte/2015/09/1...  \n",
       "3            NaN  http://www1.folha.uol.com.br/mercado/2016/09/1...  \n",
       "4            NaN  http://www1.folha.uol.com.br/cotidiano/2017/07...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artigo_teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\", disable=[\"paser\", \"ner\", \"tagger\", \"textcat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.pt.Portuguese at 0x139791ef310>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"Rio de Janeiro é uma cidade maravilhosa\"\n",
    "doc = nlp(texto)\n",
    "\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_para_tratamento = (titulos.lower() for titulos in artigo_treino['title']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x0000013971F78E40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos_para_tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_textos(doc):\n",
    "    \n",
    "    tokens_validos = []\n",
    "    for token in doc:\n",
    "        e_valido = not token.is_stop and token.is_alpha\n",
    "        if e_valido:\n",
    "            tokens_validos.append(token.text)\n",
    "    if len(tokens_validos) > 2:\n",
    "        return \" \".join(tokens_validos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rio Janeiro cidade maravilhosa'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"Rio!!!! de Janeiro afawbqw35235 é uma cidade maravilhosa 34346v!! !!!!\"\n",
    "doc = nlp(texto)\n",
    "\n",
    "trata_textos(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69798663854599\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "\n",
    "textos_tratados = [trata_textos(doc) for doc in nlp.pipe(textos_para_tratamento,\n",
    "                                                        batch_size=1000,\n",
    "                                                        n_process=3)]\n",
    "tf = time() - t0\n",
    "print(tf/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polêmica marine le pen abomina negacionistas h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>macron le pen turno frança revés siglas tradic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apesar larga vitória legislativas macron terá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>governo antecipa balanço alckmin anuncia queda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queda maio atividade econômica sobe junho bc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titulo\n",
       "0  polêmica marine le pen abomina negacionistas h...\n",
       "1  macron le pen turno frança revés siglas tradic...\n",
       "2  apesar larga vitória legislativas macron terá ...\n",
       "3  governo antecipa balanço alckmin anuncia queda...\n",
       "4       queda maio atividade econômica sobe junho bc"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titulos_tratados = pd.DataFrame({\"titulo\": textos_tratados})\n",
    "\n",
    "titulos_tratados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_modelo = Word2Vec(sg=0, window=2, vector_size=300, min_count=5, alpha=0.03, min_alpha=0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x13971f8cd90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "84466\n"
     ]
    }
   ],
   "source": [
    "print(len(titulos_tratados))\n",
    "\n",
    "titulos_tratados = titulos_tratados.dropna().drop_duplicates()\n",
    "\n",
    "print(len(titulos_tratados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_lista_tokens = [titulo.split(\" \") for titulo in titulos_tratados.titulo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:25:00,581 : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=300, alpha=0.03)', 'datetime': '2022-03-26T10:25:00.581169', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'created'}\n",
      "2022-03-26 10:25:00,582 : collecting all words and their counts\n",
      "2022-03-26 10:25:00,582 : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-26 10:25:00,589 : PROGRESS: at sentence #5000, processed 31930 words, keeping 10193 word types\n",
      "2022-03-26 10:25:00,595 : PROGRESS: at sentence #10000, processed 63848 words, keeping 14989 word types\n",
      "2022-03-26 10:25:00,601 : PROGRESS: at sentence #15000, processed 95753 words, keeping 18279 word types\n",
      "2022-03-26 10:25:00,609 : PROGRESS: at sentence #20000, processed 127689 words, keeping 21033 word types\n",
      "2022-03-26 10:25:00,616 : PROGRESS: at sentence #25000, processed 159589 words, keeping 23491 word types\n",
      "2022-03-26 10:25:00,624 : PROGRESS: at sentence #30000, processed 191554 words, keeping 25494 word types\n",
      "2022-03-26 10:25:00,631 : PROGRESS: at sentence #35000, processed 223412 words, keeping 27330 word types\n",
      "2022-03-26 10:25:00,639 : PROGRESS: at sentence #40000, processed 255282 words, keeping 29053 word types\n",
      "2022-03-26 10:25:00,646 : PROGRESS: at sentence #45000, processed 287297 words, keeping 30606 word types\n",
      "2022-03-26 10:25:00,653 : PROGRESS: at sentence #50000, processed 319258 words, keeping 31964 word types\n",
      "2022-03-26 10:25:00,660 : PROGRESS: at sentence #55000, processed 351437 words, keeping 33270 word types\n",
      "2022-03-26 10:25:00,667 : PROGRESS: at sentence #60000, processed 383579 words, keeping 34520 word types\n",
      "2022-03-26 10:25:00,675 : PROGRESS: at sentence #65000, processed 415565 words, keeping 35643 word types\n",
      "2022-03-26 10:25:00,682 : PROGRESS: at sentence #70000, processed 447646 words, keeping 36719 word types\n",
      "2022-03-26 10:25:00,689 : PROGRESS: at sentence #75000, processed 479568 words, keeping 37802 word types\n",
      "2022-03-26 10:25:00,697 : PROGRESS: at sentence #80000, processed 511645 words, keeping 38814 word types\n",
      "2022-03-26 10:25:00,704 : collected 39693 word types from a corpus of 540242 raw words and 84466 sentences\n",
      "2022-03-26 10:25:00,704 : Creating a fresh vocabulary\n",
      "2022-03-26 10:25:00,750 : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12924 unique words (32.559897211095155%% of original 39693, drops 26769)', 'datetime': '2022-03-26T10:25:00.750207', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2022-03-26 10:25:00,751 : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 495223 word corpus (91.66688261927062%% of original 540242, drops 45019)', 'datetime': '2022-03-26T10:25:00.751208', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2022-03-26 10:25:00,810 : deleting the raw counts dictionary of 39693 items\n",
      "2022-03-26 10:25:00,811 : sample=0.001 downsamples 8 most-common words\n",
      "2022-03-26 10:25:00,812 : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 486147.7552334345 word corpus (98.2%% of prior 495223)', 'datetime': '2022-03-26T10:25:00.812222', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2022-03-26 10:25:00,909 : estimated required memory for 12924 words and 300 dimensions: 37479600 bytes\n",
      "2022-03-26 10:25:00,909 : resetting layer weights\n",
      "2022-03-26 10:25:00,923 : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-26T10:25:00.923246', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'build_vocab'}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s : %(message)s\", level=logging.INFO)\n",
    "\n",
    "w2v_modelo = Word2Vec(sg=0, window=2, vector_size=300, min_count=5, alpha=0.03, min_alpha=0.007)\n",
    "\n",
    "w2v_modelo.build_vocab(lista_lista_tokens, progress_per=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84466"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:34:14,127 : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2022-03-26T10:34:14.127423', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n",
      "2022-03-26 10:34:14,471 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:14,478 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:14,481 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:14,481 : EPOCH - 1 : training on 540242 raw words (486037 effective words) took 0.3s, 1419467 effective words/s\n",
      "2022-03-26 10:34:14,828 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:14,832 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:14,834 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:14,835 : EPOCH - 2 : training on 540242 raw words (486138 effective words) took 0.3s, 1406238 effective words/s\n",
      "2022-03-26 10:34:15,177 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:15,181 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:15,186 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:15,186 : EPOCH - 3 : training on 540242 raw words (486133 effective words) took 0.3s, 1418207 effective words/s\n",
      "2022-03-26 10:34:15,533 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:15,545 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:15,548 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:15,548 : EPOCH - 4 : training on 540242 raw words (486109 effective words) took 0.4s, 1374246 effective words/s\n",
      "2022-03-26 10:34:15,888 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:15,893 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:15,897 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:15,897 : EPOCH - 5 : training on 540242 raw words (486208 effective words) took 0.3s, 1427501 effective words/s\n",
      "2022-03-26 10:34:16,247 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:16,251 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:16,262 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:16,262 : EPOCH - 6 : training on 540242 raw words (486158 effective words) took 0.4s, 1367255 effective words/s\n",
      "2022-03-26 10:34:16,603 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:16,608 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:16,614 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:16,614 : EPOCH - 7 : training on 540242 raw words (486076 effective words) took 0.3s, 1425550 effective words/s\n",
      "2022-03-26 10:34:16,956 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:16,959 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:16,963 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:16,964 : EPOCH - 8 : training on 540242 raw words (486261 effective words) took 0.3s, 1425387 effective words/s\n",
      "2022-03-26 10:34:17,297 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:17,300 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:17,304 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:17,304 : EPOCH - 9 : training on 540242 raw words (486116 effective words) took 0.3s, 1460948 effective words/s\n",
      "2022-03-26 10:34:17,644 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:17,646 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:17,650 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:17,651 : EPOCH - 10 : training on 540242 raw words (486113 effective words) took 0.3s, 1437829 effective words/s\n",
      "2022-03-26 10:34:17,984 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:17,993 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:17,998 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:17,998 : EPOCH - 11 : training on 540242 raw words (486088 effective words) took 0.3s, 1437853 effective words/s\n",
      "2022-03-26 10:34:18,335 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:18,336 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:18,343 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:18,343 : EPOCH - 12 : training on 540242 raw words (486135 effective words) took 0.3s, 1442221 effective words/s\n",
      "2022-03-26 10:34:18,683 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:18,691 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:18,694 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:18,695 : EPOCH - 13 : training on 540242 raw words (486018 effective words) took 0.3s, 1417003 effective words/s\n",
      "2022-03-26 10:34:19,029 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:19,032 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:19,037 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:19,037 : EPOCH - 14 : training on 540242 raw words (486120 effective words) took 0.3s, 1454634 effective words/s\n",
      "2022-03-26 10:34:19,368 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:19,373 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:19,376 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:19,377 : EPOCH - 15 : training on 540242 raw words (486132 effective words) took 0.3s, 1469583 effective words/s\n",
      "2022-03-26 10:34:19,716 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:19,720 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:19,723 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:19,723 : EPOCH - 16 : training on 540242 raw words (486115 effective words) took 0.3s, 1435736 effective words/s\n",
      "2022-03-26 10:34:20,054 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:20,055 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:20,058 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:20,059 : EPOCH - 17 : training on 540242 raw words (486044 effective words) took 0.3s, 1484082 effective words/s\n",
      "2022-03-26 10:34:20,390 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:20,397 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:20,399 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:20,399 : EPOCH - 18 : training on 540242 raw words (486148 effective words) took 0.3s, 1464190 effective words/s\n",
      "2022-03-26 10:34:20,730 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:20,739 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:20,742 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:20,743 : EPOCH - 19 : training on 540242 raw words (486283 effective words) took 0.3s, 1448516 effective words/s\n",
      "2022-03-26 10:34:21,075 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:21,081 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:21,084 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:21,084 : EPOCH - 20 : training on 540242 raw words (486092 effective words) took 0.3s, 1457437 effective words/s\n",
      "2022-03-26 10:34:21,412 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:21,419 : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:34:21,425 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:21,426 : EPOCH - 21 : training on 540242 raw words (486063 effective words) took 0.3s, 1458653 effective words/s\n",
      "2022-03-26 10:34:21,762 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:21,765 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:21,767 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:21,767 : EPOCH - 22 : training on 540242 raw words (486203 effective words) took 0.3s, 1458498 effective words/s\n",
      "2022-03-26 10:34:22,094 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:22,097 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:22,102 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:22,103 : EPOCH - 23 : training on 540242 raw words (486095 effective words) took 0.3s, 1484346 effective words/s\n",
      "2022-03-26 10:34:22,434 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:22,442 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:22,448 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:22,448 : EPOCH - 24 : training on 540242 raw words (486143 effective words) took 0.3s, 1442789 effective words/s\n",
      "2022-03-26 10:34:22,776 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:22,779 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:22,786 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:22,786 : EPOCH - 25 : training on 540242 raw words (486112 effective words) took 0.3s, 1473829 effective words/s\n",
      "2022-03-26 10:34:23,110 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:23,121 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:23,123 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:23,123 : EPOCH - 26 : training on 540242 raw words (486138 effective words) took 0.3s, 1476049 effective words/s\n",
      "2022-03-26 10:34:23,450 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:23,455 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:23,458 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:23,458 : EPOCH - 27 : training on 540242 raw words (486225 effective words) took 0.3s, 1486296 effective words/s\n",
      "2022-03-26 10:34:23,782 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:23,788 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:23,793 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:23,794 : EPOCH - 28 : training on 540242 raw words (486111 effective words) took 0.3s, 1486153 effective words/s\n",
      "2022-03-26 10:34:24,122 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:24,129 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:24,132 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:24,132 : EPOCH - 29 : training on 540242 raw words (486253 effective words) took 0.3s, 1470186 effective words/s\n",
      "2022-03-26 10:34:24,456 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:34:24,458 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:34:24,461 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:34:24,461 : EPOCH - 30 : training on 540242 raw words (486230 effective words) took 0.3s, 1516400 effective words/s\n",
      "2022-03-26 10:34:24,462 : Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14584097 effective words) took 10.3s, 1411292 effective words/s', 'datetime': '2022-03-26T10:34:24.461667', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14584097, 16207260)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.train(lista_lista_tokens, total_examples=w2v_modelo.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apple', 0.5758009552955627),\n",
       " ('facebook', 0.49941691756248474),\n",
       " ('uber', 0.478995680809021),\n",
       " ('airbnb', 0.4778902530670166),\n",
       " ('amazon', 0.4686358869075775),\n",
       " ('waze', 0.4567137360572815),\n",
       " ('yahoo', 0.4483999013900757),\n",
       " ('software', 0.44797152280807495),\n",
       " ('tesla', 0.42881858348846436),\n",
       " ('walmart', 0.4254896640777588)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar(\"google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amazon', 0.5588051676750183),\n",
       " ('unilever', 0.5300546288490295),\n",
       " ('tesla', 0.5299966335296631),\n",
       " ('lego', 0.5171110033988953),\n",
       " ('sky', 0.514362096786499),\n",
       " ('sony', 0.500957727432251),\n",
       " ('linkedin', 0.49670088291168213),\n",
       " ('walmart', 0.4919034242630005),\n",
       " ('spotify', 0.48614799976348877),\n",
       " ('braskem', 0.4860401749610901)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar(\"microsoft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bayern', 0.5852482914924622),\n",
       " ('madrid', 0.5567420125007629),\n",
       " ('barça', 0.5556893348693848),\n",
       " ('lazio', 0.547187864780426),\n",
       " ('united', 0.5313367247581482),\n",
       " ('chelsea', 0.5310776233673096),\n",
       " ('juventus', 0.53084397315979),\n",
       " ('psg', 0.5278435349464417),\n",
       " ('munique', 0.5120042562484741),\n",
       " ('monaco', 0.5062684416770935)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar(\"barcelona\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('suárez', 0.5980156064033508),\n",
       " ('cristiano', 0.5251968502998352),\n",
       " ('tevez', 0.5231528282165527),\n",
       " ('chuteiras', 0.5215114951133728),\n",
       " ('benzema', 0.5139065384864807),\n",
       " ('cavani', 0.5078448057174683),\n",
       " ('enrique', 0.49318912625312805),\n",
       " ('barcelona', 0.48997893929481506),\n",
       " ('ronaldo', 0.4858036935329437),\n",
       " ('psg', 0.4857817590236664)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar(\"messi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('volks', 0.6646945476531982),\n",
       " ('embraer', 0.6124216318130493),\n",
       " ('chrysler', 0.5999782681465149),\n",
       " ('honda', 0.5883104801177979),\n",
       " ('braskem', 0.5850892066955566),\n",
       " ('volkswagen', 0.574164867401123),\n",
       " ('csn', 0.5720359683036804),\n",
       " ('fiat', 0.5579571723937988),\n",
       " ('mitsubishi', 0.5531455278396606),\n",
       " ('sony', 0.5508740544319153)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar(\"gm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de Loss\n",
    "\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# iniciando a chamada callback\n",
    "class callback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss após a época {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss após a época {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:01,535 : Effective 'alpha' higher than previous training cycles\n",
      "2022-03-26 10:40:01,536 : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2022-03-26T10:40:01.536263', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n",
      "2022-03-26 10:40:01,852 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:01,857 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:01,860 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:01,861 : EPOCH - 1 : training on 540242 raw words (486160 effective words) took 0.3s, 1541722 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 0: 141112.515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:02,182 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:02,187 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:02,189 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:02,190 : EPOCH - 2 : training on 540242 raw words (486178 effective words) took 0.3s, 1515226 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 1: 137801.171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:02,514 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:02,520 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:02,523 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:02,523 : EPOCH - 3 : training on 540242 raw words (486116 effective words) took 0.3s, 1490864 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 2: 131629.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:02,846 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:02,851 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:02,854 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:02,854 : EPOCH - 4 : training on 540242 raw words (485991 effective words) took 0.3s, 1507507 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 3: 126246.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:03,168 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:03,173 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:03,176 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:03,176 : EPOCH - 5 : training on 540242 raw words (486026 effective words) took 0.3s, 1543998 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 4: 119639.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:03,495 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:03,501 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:03,504 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:03,504 : EPOCH - 6 : training on 540242 raw words (486103 effective words) took 0.3s, 1525771 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 5: 115130.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:03,820 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:03,825 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:03,828 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:03,828 : EPOCH - 7 : training on 540242 raw words (486186 effective words) took 0.3s, 1541079 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 6: 111261.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:04,143 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:04,149 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:04,151 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:04,152 : EPOCH - 8 : training on 540242 raw words (486083 effective words) took 0.3s, 1537788 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 7: 107486.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:04,468 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:04,474 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:04,478 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:04,478 : EPOCH - 9 : training on 540242 raw words (486222 effective words) took 0.3s, 1527875 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 8: 102917.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:04,793 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:04,796 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:04,798 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:04,799 : EPOCH - 10 : training on 540242 raw words (486266 effective words) took 0.3s, 1557008 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 9: 99173.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:05,112 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:05,115 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:05,118 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:05,118 : EPOCH - 11 : training on 540242 raw words (486163 effective words) took 0.3s, 1560097 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 10: 95542.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:05,432 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:05,435 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:05,441 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:05,442 : EPOCH - 12 : training on 540242 raw words (486179 effective words) took 0.3s, 1548039 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 11: 92626.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:05,752 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:05,760 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:05,763 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:05,764 : EPOCH - 13 : training on 540242 raw words (486055 effective words) took 0.3s, 1548939 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 12: 90668.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:06,073 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:06,079 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:06,082 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:06,083 : EPOCH - 14 : training on 540242 raw words (486213 effective words) took 0.3s, 1563179 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 13: 88831.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:06,391 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:06,397 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:06,400 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:06,401 : EPOCH - 15 : training on 540242 raw words (486155 effective words) took 0.3s, 1577046 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 14: 86576.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:06,711 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:06,718 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:06,721 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:06,722 : EPOCH - 16 : training on 540242 raw words (486283 effective words) took 0.3s, 1553859 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 15: 84808.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:07,032 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:07,037 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:07,045 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:07,045 : EPOCH - 17 : training on 540242 raw words (486139 effective words) took 0.3s, 1541478 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 16: 83517.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:07,355 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:07,363 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:07,366 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:07,366 : EPOCH - 18 : training on 540242 raw words (486244 effective words) took 0.3s, 1559020 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 17: 81407.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:07,683 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:07,684 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:07,687 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:07,688 : EPOCH - 19 : training on 540242 raw words (486270 effective words) took 0.3s, 1542091 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 18: 80209.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:07,999 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:08,005 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:08,009 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:08,009 : EPOCH - 20 : training on 540242 raw words (486114 effective words) took 0.3s, 1551975 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 19: 78426.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:08,320 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:08,326 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:08,329 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:08,329 : EPOCH - 21 : training on 540242 raw words (486198 effective words) took 0.3s, 1558398 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 20: 74983.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:08,638 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:08,643 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:08,646 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:08,647 : EPOCH - 22 : training on 540242 raw words (486231 effective words) took 0.3s, 1572904 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 21: 71304.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:08,959 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:08,962 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:08,971 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:08,971 : EPOCH - 23 : training on 540242 raw words (486086 effective words) took 0.3s, 1534086 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 22: 70256.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:09,279 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:09,284 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:09,287 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:09,287 : EPOCH - 24 : training on 540242 raw words (486154 effective words) took 0.3s, 1581161 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 23: 69400.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:09,594 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:09,597 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:09,603 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:09,603 : EPOCH - 25 : training on 540242 raw words (486081 effective words) took 0.3s, 1576746 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 24: 67833.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:09,910 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:09,918 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:09,920 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:09,921 : EPOCH - 26 : training on 540242 raw words (486101 effective words) took 0.3s, 1570069 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 25: 66643.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:10,228 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:10,232 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:10,235 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:10,236 : EPOCH - 27 : training on 540242 raw words (486073 effective words) took 0.3s, 1581716 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 26: 66223.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:10,541 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:10,544 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:10,547 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:10,547 : EPOCH - 28 : training on 540242 raw words (486181 effective words) took 0.3s, 1606699 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 27: 65481.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:10,854 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:10,864 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:10,866 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:10,866 : EPOCH - 29 : training on 540242 raw words (486176 effective words) took 0.3s, 1564415 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 28: 64718.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:40:11,178 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:40:11,180 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:40:11,183 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:40:11,183 : EPOCH - 30 : training on 540242 raw words (486049 effective words) took 0.3s, 1570730 effective words/s\n",
      "2022-03-26 10:40:11,184 : Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14584476 effective words) took 9.6s, 1511698 effective words/s', 'datetime': '2022-03-26T10:40:11.183592', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 29: 63562.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14584476, 16207260)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.train(lista_lista_tokens,\n",
    "                total_examples=w2v_modelo.corpus_count,\n",
    "                epochs = 30,\n",
    "                compute_loss = True,\n",
    "                callbacks=[callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:46:00,204 : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=300, alpha=0.03)', 'datetime': '2022-03-26T10:46:00.204335', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'created'}\n",
      "2022-03-26 10:46:00,205 : collecting all words and their counts\n",
      "2022-03-26 10:46:00,205 : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-26 10:46:00,211 : PROGRESS: at sentence #5000, processed 31930 words, keeping 10193 word types\n",
      "2022-03-26 10:46:00,217 : PROGRESS: at sentence #10000, processed 63848 words, keeping 14989 word types\n",
      "2022-03-26 10:46:00,223 : PROGRESS: at sentence #15000, processed 95753 words, keeping 18279 word types\n",
      "2022-03-26 10:46:00,230 : PROGRESS: at sentence #20000, processed 127689 words, keeping 21033 word types\n",
      "2022-03-26 10:46:00,237 : PROGRESS: at sentence #25000, processed 159589 words, keeping 23491 word types\n",
      "2022-03-26 10:46:00,245 : PROGRESS: at sentence #30000, processed 191554 words, keeping 25494 word types\n",
      "2022-03-26 10:46:00,252 : PROGRESS: at sentence #35000, processed 223412 words, keeping 27330 word types\n",
      "2022-03-26 10:46:00,260 : PROGRESS: at sentence #40000, processed 255282 words, keeping 29053 word types\n",
      "2022-03-26 10:46:00,267 : PROGRESS: at sentence #45000, processed 287297 words, keeping 30606 word types\n",
      "2022-03-26 10:46:00,274 : PROGRESS: at sentence #50000, processed 319258 words, keeping 31964 word types\n",
      "2022-03-26 10:46:00,282 : PROGRESS: at sentence #55000, processed 351437 words, keeping 33270 word types\n",
      "2022-03-26 10:46:00,289 : PROGRESS: at sentence #60000, processed 383579 words, keeping 34520 word types\n",
      "2022-03-26 10:46:00,296 : PROGRESS: at sentence #65000, processed 415565 words, keeping 35643 word types\n",
      "2022-03-26 10:46:00,304 : PROGRESS: at sentence #70000, processed 447646 words, keeping 36719 word types\n",
      "2022-03-26 10:46:00,311 : PROGRESS: at sentence #75000, processed 479568 words, keeping 37802 word types\n",
      "2022-03-26 10:46:00,318 : PROGRESS: at sentence #80000, processed 511645 words, keeping 38814 word types\n",
      "2022-03-26 10:46:00,325 : collected 39693 word types from a corpus of 540242 raw words and 84466 sentences\n",
      "2022-03-26 10:46:00,325 : Creating a fresh vocabulary\n",
      "2022-03-26 10:46:00,372 : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12924 unique words (32.559897211095155%% of original 39693, drops 26769)', 'datetime': '2022-03-26T10:46:00.372373', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2022-03-26 10:46:00,372 : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 495223 word corpus (91.66688261927062%% of original 540242, drops 45019)', 'datetime': '2022-03-26T10:46:00.372373', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2022-03-26 10:46:00,432 : deleting the raw counts dictionary of 39693 items\n",
      "2022-03-26 10:46:00,433 : sample=0.001 downsamples 8 most-common words\n",
      "2022-03-26 10:46:00,433 : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 486147.7552334345 word corpus (98.2%% of prior 495223)', 'datetime': '2022-03-26T10:46:00.433387', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2022-03-26 10:46:00,530 : estimated required memory for 12924 words and 300 dimensions: 37479600 bytes\n",
      "2022-03-26 10:46:00,530 : resetting layer weights\n",
      "2022-03-26 10:46:00,544 : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-26T10:46:00.544413', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'build_vocab'}\n",
      "2022-03-26 10:46:00,545 : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-26T10:46:00.545413', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n",
      "2022-03-26 10:46:01,339 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:01,348 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:01,350 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:01,351 : EPOCH - 1 : training on 540242 raw words (486139 effective words) took 0.8s, 609317 effective words/s\n",
      "2022-03-26 10:46:02,146 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:02,155 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:02,160 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:02,161 : EPOCH - 2 : training on 540242 raw words (486116 effective words) took 0.8s, 606176 effective words/s\n",
      "2022-03-26 10:46:02,951 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:02,953 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:02,963 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:02,963 : EPOCH - 3 : training on 540242 raw words (486058 effective words) took 0.8s, 611754 effective words/s\n",
      "2022-03-26 10:46:03,758 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:03,759 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:03,765 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:03,765 : EPOCH - 4 : training on 540242 raw words (486136 effective words) took 0.8s, 613314 effective words/s\n",
      "2022-03-26 10:46:04,555 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:04,557 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:04,560 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:04,560 : EPOCH - 5 : training on 540242 raw words (486185 effective words) took 0.8s, 617674 effective words/s\n",
      "2022-03-26 10:46:05,356 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:05,356 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:05,358 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:05,358 : EPOCH - 6 : training on 540242 raw words (486289 effective words) took 0.8s, 615172 effective words/s\n",
      "2022-03-26 10:46:06,144 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:06,154 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:06,157 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:06,157 : EPOCH - 7 : training on 540242 raw words (486102 effective words) took 0.8s, 614703 effective words/s\n",
      "2022-03-26 10:46:06,948 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:06,963 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:06,965 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:06,965 : EPOCH - 8 : training on 540242 raw words (486103 effective words) took 0.8s, 607525 effective words/s\n",
      "2022-03-26 10:46:07,750 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:07,752 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:07,754 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:07,755 : EPOCH - 9 : training on 540242 raw words (486196 effective words) took 0.8s, 622825 effective words/s\n",
      "2022-03-26 10:46:08,538 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:08,539 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:08,553 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:08,553 : EPOCH - 10 : training on 540242 raw words (486170 effective words) took 0.8s, 614831 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:46:09,341 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:09,343 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:09,346 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:09,346 : EPOCH - 11 : training on 540242 raw words (486245 effective words) took 0.8s, 619492 effective words/s\n",
      "2022-03-26 10:46:10,138 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:10,149 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:10,153 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:10,154 : EPOCH - 12 : training on 540242 raw words (486198 effective words) took 0.8s, 608960 effective words/s\n",
      "2022-03-26 10:46:10,933 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:10,935 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:10,937 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:10,938 : EPOCH - 13 : training on 540242 raw words (486153 effective words) took 0.8s, 626729 effective words/s\n",
      "2022-03-26 10:46:11,730 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:11,737 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:11,740 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:11,740 : EPOCH - 14 : training on 540242 raw words (486207 effective words) took 0.8s, 612571 effective words/s\n",
      "2022-03-26 10:46:12,512 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:12,515 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:12,528 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:12,529 : EPOCH - 15 : training on 540242 raw words (486255 effective words) took 0.8s, 622807 effective words/s\n",
      "2022-03-26 10:46:13,298 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:13,306 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:13,309 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:13,309 : EPOCH - 16 : training on 540242 raw words (486150 effective words) took 0.8s, 629534 effective words/s\n",
      "2022-03-26 10:46:14,077 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:14,093 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:14,098 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:14,099 : EPOCH - 17 : training on 540242 raw words (486085 effective words) took 0.8s, 621844 effective words/s\n",
      "2022-03-26 10:46:14,875 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:14,890 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:14,894 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:14,894 : EPOCH - 18 : training on 540242 raw words (486229 effective words) took 0.8s, 617808 effective words/s\n",
      "2022-03-26 10:46:15,660 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:15,674 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:15,676 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:15,677 : EPOCH - 19 : training on 540242 raw words (486196 effective words) took 0.8s, 628058 effective words/s\n",
      "2022-03-26 10:46:16,454 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:16,458 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:16,476 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:16,477 : EPOCH - 20 : training on 540242 raw words (486170 effective words) took 0.8s, 615321 effective words/s\n",
      "2022-03-26 10:46:17,232 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:17,244 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:17,248 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:17,248 : EPOCH - 21 : training on 540242 raw words (486111 effective words) took 0.8s, 637076 effective words/s\n",
      "2022-03-26 10:46:18,010 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:18,012 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:18,014 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:18,014 : EPOCH - 22 : training on 540242 raw words (486133 effective words) took 0.8s, 640808 effective words/s\n",
      "2022-03-26 10:46:18,772 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:18,776 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:18,790 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:18,790 : EPOCH - 23 : training on 540242 raw words (486183 effective words) took 0.8s, 633150 effective words/s\n",
      "2022-03-26 10:46:19,545 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:19,553 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:19,555 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:19,556 : EPOCH - 24 : training on 540242 raw words (486136 effective words) took 0.8s, 642061 effective words/s\n",
      "2022-03-26 10:46:20,305 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:20,307 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:20,310 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:20,310 : EPOCH - 25 : training on 540242 raw words (486031 effective words) took 0.7s, 651176 effective words/s\n",
      "2022-03-26 10:46:21,067 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:21,073 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:21,079 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:21,079 : EPOCH - 26 : training on 540242 raw words (486189 effective words) took 0.8s, 638408 effective words/s\n",
      "2022-03-26 10:46:21,853 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:21,854 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:21,856 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:21,856 : EPOCH - 27 : training on 540242 raw words (486172 effective words) took 0.8s, 632256 effective words/s\n",
      "2022-03-26 10:46:22,604 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:22,607 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:22,627 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:22,627 : EPOCH - 28 : training on 540242 raw words (486091 effective words) took 0.8s, 636803 effective words/s\n",
      "2022-03-26 10:46:23,367 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:23,376 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:23,377 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:23,377 : EPOCH - 29 : training on 540242 raw words (486030 effective words) took 0.7s, 657185 effective words/s\n",
      "2022-03-26 10:46:24,121 : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-26 10:46:24,122 : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-26 10:46:24,122 : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-26 10:46:24,122 : EPOCH - 30 : training on 540242 raw words (486150 effective words) took 0.7s, 659460 effective words/s\n",
      "2022-03-26 10:46:24,123 : Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14584608 effective words) took 23.6s, 618587 effective words/s', 'datetime': '2022-03-26T10:46:24.123272', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14584608, 16207260)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Treinamento do modelo Skip-Gram\n",
    "\n",
    "w2v_modelo_sg = Word2Vec(sg=1, window=5, vector_size=300, min_count=5, alpha=0.03, min_alpha=0.007)\n",
    "\n",
    "w2v_modelo_sg.build_vocab(lista_lista_tokens, progress_per=5000)\n",
    "\n",
    "w2v_modelo_sg.train(lista_lista_tokens, total_examples=w2v_modelo_sg.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reguladores', 0.4349759817123413),\n",
       " ('android', 0.415201336145401),\n",
       " ('apple', 0.3931206464767456),\n",
       " ('waze', 0.3836930990219116),\n",
       " ('anunciantes', 0.38210171461105347),\n",
       " ('facebook', 0.37446630001068115),\n",
       " ('anúncios', 0.367348849773407),\n",
       " ('yahoo', 0.36428165435791016),\n",
       " ('toshiba', 0.36216428875923157),\n",
       " ('buffett', 0.35644641518592834)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo_sg.wv.most_similar(\"google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('metalúrgicos', 0.5394555330276489),\n",
       " ('motors', 0.5371218919754028),\n",
       " ('audi', 0.4800618886947632),\n",
       " ('honda', 0.4688883423805237),\n",
       " ('autoguiados', 0.46044448018074036),\n",
       " ('cubatão', 0.4578298330307007),\n",
       " ('volkswagen', 0.454934686422348),\n",
       " ('airbag', 0.45408231019973755),\n",
       " ('coletivas', 0.4534090459346771),\n",
       " ('bmw', 0.4530266225337982)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo_sg.wv.most_similar(\"gm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 10:53:32,506 : storing 12924x300 projection weights into modelo_cbow.txt\n",
      "2022-03-26 10:53:34,345 : storing 12924x300 projection weights into modelo_skipgram.txt\n"
     ]
    }
   ],
   "source": [
    "# Salvando modelos\n",
    "w2v_modelo.wv.save_word2vec_format(\"modelo_cbow.txt\", binary=False)\n",
    "w2v_modelo_sg.wv.save_word2vec_format(\"modelo_skipgram.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 11:20:57,501 : loading projection weights from modelo_cbow.txt\n",
      "2022-03-26 11:20:59,515 : KeyedVectors lifecycle event {'msg': 'loaded (12924, 300) matrix of type float32 from modelo_cbow.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2022-03-26T11:20:59.515540', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'load_word2vec_format'}\n",
      "2022-03-26 11:20:59,516 : loading projection weights from modelo_skipgram.txt\n",
      "2022-03-26 11:21:01,547 : KeyedVectors lifecycle event {'msg': 'loaded (12924, 300) matrix of type float32 from modelo_skipgram.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2022-03-26T11:21:01.545999', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "# Carregando modelos\n",
    "w2v_modelo_cbow = KeyedVectors.load_word2vec_format(\"modelo_cbow.txt\")\n",
    "w2v_modelo_sg = KeyedVectors.load_word2vec_format(\"modelo_skipgram.txt\")\n",
    "\n",
    "artigo_treino = pd.read_csv(\"treino.csv\")\n",
    "artigo_teste = pd.read_csv(\"teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0X5lI4-NSlRI",
    "outputId": "04266ca0-0d79-4016-877a-7b66480859e4"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\", disable=[\"paser\", \"ner\", \"tagger\", \"textcat\"])\n",
    "\n",
    "def tokenizador(texto):\n",
    "    \n",
    "    doc = nlp(texto)\n",
    "    tokens_validos = []\n",
    "    for token in doc:\n",
    "        e_valido = not token.is_stop and token.is_alpha\n",
    "        if e_valido:\n",
    "            tokens_validos.append(token.text.lower())\n",
    "\n",
    "    return tokens_validos\n",
    "\n",
    "texto = \"Rio de Janeiro 1231231 ***** @#$ é uma cidade maravilhosa!\"\n",
    "tokens = tokenizador(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rio', 'janeiro', 'cidade', 'maravilhosa']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2_GCypILSVga",
    "outputId": "012711bc-b25b-41fe-ec06-188041c70091"
   },
   "outputs": [],
   "source": [
    "def combinacao_de_vetores_por_soma(palavras, modelo):\n",
    "\n",
    "    vetor_resultante = np.zeros((1,300))\n",
    "    for pn in palavras:\n",
    "        try:\n",
    "            vetor_resultante += modelo.get_vector(pn)\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "                \n",
    "    return vetor_resultante\n",
    "\n",
    "vetor_texto = combinacao_de_vetores_por_soma(tokens, w2v_modelo_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300)\n"
     ]
    }
   ],
   "source": [
    "print(vetor_texto.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73725584  0.15089217  1.20240411 -2.18453644  1.13463244  0.8708794\n",
      "  -2.41565949 -0.83435117  1.14251167 -0.64286306  2.11320369  1.46362174\n",
      "  -1.02735598  0.31004089 -0.83100927 -2.64782354 -0.35581958 -1.61779478\n",
      "   0.99951565  0.95883645 -0.16870557 -2.24236462 -1.4092429   0.01914283\n",
      "   0.10256626 -2.61562097  1.38824315  0.25425192  1.43732762  1.27734546\n",
      "  -0.54301734 -2.74001928  0.31866984  3.04808322  2.48002577  0.09407444\n",
      "  -3.21189892 -1.77520654  0.51419392 -1.17501896  0.09438811  0.72211311\n",
      "   1.19624677 -1.38036093 -3.07582545  0.03012702  2.59406152 -2.47521687\n",
      "   1.67371193 -1.68280038 -2.69250438 -1.67408818  1.21550885 -1.51341188\n",
      "  -0.88308096  1.26416854  0.63714375 -1.94227734  1.30572701 -0.46578476\n",
      "  -1.1800946  -3.59368235  1.38035727 -1.49303861  2.47762886 -0.14134818\n",
      "  -0.15565002  1.01091149  0.96781203 -1.39987681  0.43151861  1.83797364\n",
      "  -0.30938169  0.84137964  1.61296211  1.65670627  1.47859338  0.14305029\n",
      "  -2.0172189   0.4674986  -0.84957802  2.02121027 -1.91208351 -0.44945082\n",
      "  -0.57040655 -0.79403564  0.6295452   0.34203786  0.2337104  -0.33347746\n",
      "   0.0371327   0.57777314 -2.09088556 -1.49043438 -0.96143842  1.68939999\n",
      "   0.62317631 -0.01270486 -0.91044593  3.05463016  0.86380056  0.41728154\n",
      "   0.62393928  0.33032253 -1.80323306  2.48066075 -0.95353878  1.21986881\n",
      "  -0.65928139  0.37759054  0.27432206 -0.24174924 -0.18188256 -1.81875768\n",
      "   1.09298667 -1.46435195  1.1248309  -0.93163066 -2.74252689 -1.1267322\n",
      "   2.35579287 -0.31498879  1.07347547  1.08826376  0.37775291  4.48688328\n",
      "  -2.83916162 -2.11326405 -0.87849727  5.18801543  3.48537445 -1.51516723\n",
      "   2.04628253  0.31085519 -0.39705358 -1.60466853 -1.713512    3.34829415\n",
      "   0.86466658 -0.24589899 -2.04647325 -1.35267134  1.97903836  1.18125898\n",
      "   0.47681591 -2.22817651 -0.90031609  0.57272723 -0.08268062  1.13629238\n",
      "  -0.3616709  -3.6336506  -0.52352855 -0.17835362  1.59493017  0.15750336\n",
      "   1.40451644  0.36065075 -0.62790778  3.59090877  0.70388594  1.1444998\n",
      "   2.27069698 -1.27654159  2.42374822  1.352734   -1.15082416  0.98375368\n",
      "   1.02650397  0.85462243  0.53912521  0.51438498 -1.94279389 -0.87025154\n",
      "   0.82466501 -0.24278956  1.10482327  0.79700145  1.28403567 -0.28270787\n",
      "   0.98126183 -0.86866328 -0.49323452 -0.26001477  0.3139568  -0.37507915\n",
      "  -0.50779837  1.88611016  1.12737581  0.40041435  0.88006154  3.04089731\n",
      "   0.44786025 -0.53888642 -3.01782066 -0.32278921  1.71767189 -1.02465345\n",
      "   0.3490214   0.22699891 -1.77592134  0.91188001  1.02867858  1.30866158\n",
      "   1.79437312  0.17823458  2.4038745   2.76076191  1.87936254 -2.5544951\n",
      "   0.21985814 -0.06198588 -3.191167    0.39572811 -0.48308271 -0.35247877\n",
      "   2.24457043  0.25084931  0.07660721 -2.03608125 -1.6407533   1.25510581\n",
      "   1.69813087 -0.97518022 -2.55377281  2.6168671   1.9357262  -1.62387621\n",
      "  -1.22080497 -0.08762774 -1.45303304 -2.47700262  0.5013319  -0.01930901\n",
      "  -1.24081892 -1.4685908  -1.89699283 -2.01155384 -0.80619757  1.07068922\n",
      "   1.65518621 -1.08725977  2.39512444 -1.42238901  2.05367672 -0.73495901\n",
      "  -1.86883125  0.76117915 -1.33859318 -4.05334073  0.01271661  2.02166176\n",
      "   3.25817126 -1.11515671  0.29503661 -0.48413125  0.42537647 -1.54928327\n",
      "  -3.84291768 -1.50081028 -0.73181191 -1.55613971  1.16962559  0.44980595\n",
      "   0.07744259 -2.03729448 -0.31766587 -0.73407546 -5.32356372 -5.11325133\n",
      "  -1.78309172  3.40947524  0.87908398  1.48712313 -0.86541851 -0.49015233\n",
      "   2.8507306   0.63937259 -1.02885386 -1.40962307 -2.4781588  -0.34861627\n",
      "  -2.03683388  0.65296474  3.96741646 -0.12053716 -0.53184566 -2.43755695\n",
      "  -1.07887197 -1.24522756 -0.07446888  1.98879412 -0.23774363  3.11377735\n",
      "   0.1960564  -1.33156407  0.76561683  1.47971684  2.70609629  1.54563132]]\n"
     ]
    }
   ],
   "source": [
    "print(vetor_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "CSXjHM9sSQY8",
    "outputId": "74f5a18c-daed-40ee-cd07-b3a80806086f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 300)\n",
      "(20513, 300)\n"
     ]
    }
   ],
   "source": [
    "def matriz_vetores(textos, modelo):\n",
    "    x = len(textos)\n",
    "    y = 300\n",
    "    matriz = np.zeros((x,y))\n",
    "\n",
    "    for i in range(x):\n",
    "        palavras = tokenizador(textos.iloc[i])\n",
    "        matriz[i] = combinacao_de_vetores_por_soma(palavras, modelo)\n",
    "\n",
    "    return matriz\n",
    "\n",
    "matriz_vetores_treino_cbow = matriz_vetores(artigo_treino.title, w2v_modelo_cbow)\n",
    "matriz_vetores_teste_cbow = matriz_vetores(artigo_teste.title, w2v_modelo_cbow)\n",
    "\n",
    "print(matriz_vetores_treino_cbow.shape)\n",
    "print(matriz_vetores_teste_cbow.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "tr5VDmj3lkf0",
    "outputId": "bd25ca15-9b5f-43cb-dab1-00df472b69b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     colunas       0.80      0.71      0.75      6103\n",
      "   cotidiano       0.63      0.80      0.70      1698\n",
      "     esporte       0.93      0.87      0.89      4663\n",
      "   ilustrada       0.13      0.86      0.23       131\n",
      "     mercado       0.84      0.78      0.81      5867\n",
      "       mundo       0.74      0.83      0.78      2051\n",
      "\n",
      "    accuracy                           0.79     20513\n",
      "   macro avg       0.68      0.81      0.69     20513\n",
      "weighted avg       0.82      0.79      0.80     20513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def classificador(modelo, x_treino, y_treino, x_teste, y_teste):\n",
    "\n",
    "    RL = LogisticRegression(max_iter = 800)\n",
    "    RL.fit(x_treino, y_treino)\n",
    "    categorias = RL.predict(x_teste)\n",
    "    resultados = classification_report(y_teste, categorias)\n",
    "    print(resultados)\n",
    "    \n",
    "    return RL\n",
    "\n",
    "RL_cbow = classificador(w2v_modelo_cbow,\n",
    "                        matriz_vetores_treino_cbow,\n",
    "                        artigo_treino.category,\n",
    "                        matriz_vetores_teste_cbow,\n",
    "                        artigo_teste.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "WlKOJ9AGsseD",
    "outputId": "120d2f70-2fb9-4c7d-eb46-761e9ac35939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     colunas       0.81      0.71      0.76      6103\n",
      "   cotidiano       0.64      0.81      0.71      1698\n",
      "     esporte       0.93      0.87      0.90      4663\n",
      "   ilustrada       0.14      0.86      0.24       131\n",
      "     mercado       0.84      0.79      0.82      5867\n",
      "       mundo       0.75      0.84      0.79      2051\n",
      "\n",
      "    accuracy                           0.79     20513\n",
      "   macro avg       0.69      0.81      0.70     20513\n",
      "weighted avg       0.82      0.79      0.80     20513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matriz_vetores_treino_sg = matriz_vetores(artigo_treino.title, w2v_modelo_sg)\n",
    "matriz_vetores_teste_sg = matriz_vetores(artigo_teste.title, w2v_modelo_sg)\n",
    "\n",
    "RL_sg = classificador(w2v_modelo_sg,\n",
    "                      matriz_vetores_treino_sg,\n",
    "                      artigo_treino.category,\n",
    "                      matriz_vetores_teste_sg,\n",
    "                      artigo_teste.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q8mAwV5ctfxI"
   },
   "outputs": [],
   "source": [
    "# Salvando modelo\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"rl_cbow.pkl\", \"wb\") as f:\n",
    "    pickle.dump(RL_cbow, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Y6OxXfNwzuz"
   },
   "outputs": [],
   "source": [
    "with open(\"rl_sg.pkl\", \"wb\") as f:\n",
    "    pickle.dump(RL_sg, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Aula06_w2v.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
