{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe6f464",
   "metadata": {},
   "source": [
    "<img src = \"https://images2.imgbox.com/32/ac/wucGkuem_o.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45947431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "# importando um corpus textual\n",
    "with open(\"artigos.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    artigos = f.read()\n",
    "\n",
    "print(artigos[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac35bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_exemplo = \"Olá, tudo bem?\"\n",
    "palavras_separadas = texto_exemplo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b039a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá,', 'tudo', 'bem?']\n"
     ]
    }
   ],
   "source": [
    "print(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e9012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(palavras_separadas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df5d7d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dsc70\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee87fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá', ',', 'tudo', 'bem', '?']\n"
     ]
    }
   ],
   "source": [
    "# Tokenização\n",
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)\n",
    "print(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d204f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'tudo', 'bem']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separando palavras em tokens\n",
    "\n",
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras\n",
    "\n",
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf5325d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de palavras é 403104\n"
     ]
    }
   ],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "\n",
    "print(f\"O número de palavras é {len(lista_palavras)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6ff432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'Temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(lista_palavras[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5986f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no']\n"
     ]
    }
   ],
   "source": [
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada\n",
    "\n",
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "\n",
    "print(lista_normalizada[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eeb624d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18465"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lista_normalizada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ea11f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'àlgica', 'álgica', 'âlgica', 'ãlgica', 'èlgica', 'élgica', 'êlgica', 'ìlgica', 'ílgica', 'îlgica', 'òlgica', 'ólgica', 'ôlgica', 'õlgica', 'ùlgica', 'úlgica', 'ûlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'làgica', 'lágica', 'lâgica', 'lãgica', 'lègica', 'légica', 'lêgica', 'lìgica', 'lígica', 'lîgica', 'lògica', 'lógica', 'lôgica', 'lõgica', 'lùgica', 'lúgica', 'lûgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgàica', 'lgáica', 'lgâica', 'lgãica', 'lgèica', 'lgéica', 'lgêica', 'lgìica', 'lgíica', 'lgîica', 'lgòica', 'lgóica', 'lgôica', 'lgõica', 'lgùica', 'lgúica', 'lgûica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiàca', 'lgiáca', 'lgiâca', 'lgiãca', 'lgièca', 'lgiéca', 'lgiêca', 'lgiìca', 'lgiíca', 'lgiîca', 'lgiòca', 'lgióca', 'lgiôca', 'lgiõca', 'lgiùca', 'lgiúca', 'lgiûca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicàa', 'lgicáa', 'lgicâa', 'lgicãa', 'lgicèa', 'lgicéa', 'lgicêa', 'lgicìa', 'lgicía', 'lgicîa', 'lgicòa', 'lgicóa', 'lgicôa', 'lgicõa', 'lgicùa', 'lgicúa', 'lgicûa', 'lgicça', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaà', 'lgicaá', 'lgicaâ', 'lgicaã', 'lgicaè', 'lgicaé', 'lgicaê', 'lgicaì', 'lgicaí', 'lgicaî', 'lgicaò', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaù', 'lgicaú', 'lgicaû', 'lgicaç']\n"
     ]
    }
   ],
   "source": [
    "palavra_exemplo = \"lgica\"\n",
    "\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "251bbcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 15502),\n",
       " ('o', 14056),\n",
       " ('que', 12230),\n",
       " ('a', 11099),\n",
       " ('e', 10501),\n",
       " ('para', 7710),\n",
       " ('um', 6368),\n",
       " ('é', 5899),\n",
       " ('uma', 5220),\n",
       " ('do', 5124)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "total_palavras = len(lista_normalizada)\n",
    "frequencia.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "889eb09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00023815194093831864\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada]/total_palavras\n",
    "\n",
    "print(probabilidade(\"lógica\"))\n",
    "print(probabilidade(\"lagica\"))\n",
    "print(probabilidade(\"logica\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32baa5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lógica\n"
     ]
    }
   ],
   "source": [
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "palavra_correta = corretor(palavra_exemplo)\n",
    "print(palavra_correta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6764d81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('podemos', 'pyodemos'),\n",
       " ('esse', 'esje'),\n",
       " ('já', 'jrá'),\n",
       " ('nosso', 'nossov'),\n",
       " ('são', 'sãêo'),\n",
       " ('dos', 'dosa'),\n",
       " ('muito', 'muifo'),\n",
       " ('imagem', 'iômagem'),\n",
       " ('sua', 'ósua'),\n",
       " ('também', 'tambéùm'),\n",
       " ('ele', 'eme'),\n",
       " ('fazer', 'èazer'),\n",
       " ('temos', 'temfs'),\n",
       " ('essa', 'eàssa'),\n",
       " ('quando', 'quaôdo'),\n",
       " ('vamos', 'vamvos'),\n",
       " ('sobre', 'hsobre'),\n",
       " ('java', 'sjava'),\n",
       " ('das', 'daõs'),\n",
       " ('agora', 'agorah'),\n",
       " ('está', 'eòtá'),\n",
       " ('cada', 'céda'),\n",
       " ('mesmo', 'zmesmo'),\n",
       " ('nos', 'noâ'),\n",
       " ('forma', 'fobma'),\n",
       " ('seja', 'sejéa'),\n",
       " ('então', 'enêão'),\n",
       " ('criar', 'èriar'),\n",
       " ('código', 'cóeigo'),\n",
       " ('caso', 'casío'),\n",
       " ('exemplo', 'áexemplo'),\n",
       " ('tem', 'tĩem'),\n",
       " ('usuário', 'usuárôio'),\n",
       " ('dados', 'dfados'),\n",
       " ('python', 'pgthon'),\n",
       " ('nossa', 'nossah'),\n",
       " ('além', 'alémè'),\n",
       " ('assim', 'asõim'),\n",
       " ('ter', 'teb'),\n",
       " ('até', 'atĩ'),\n",
       " ('bem', 'âem'),\n",
       " ('design', 'desigen'),\n",
       " ('trabalho', 'trabalàho'),\n",
       " ('foi', 'foo'),\n",
       " ('apenas', 'apenaũ'),\n",
       " ('empresa', 'empresà'),\n",
       " ('valor', 'valíor'),\n",
       " ('será', 'serr'),\n",
       " ('entre', 'entke'),\n",
       " ('método', 'méqodo'),\n",
       " ('precisamos', 'precisamops'),\n",
       " ('ainda', 'ainàa'),\n",
       " ('vai', 'van'),\n",
       " ('conteúdo', 'ûconteúdo'),\n",
       " ('seus', 'çeus'),\n",
       " ('eu', 'eû'),\n",
       " ('todos', 'todtos'),\n",
       " ('tempo', 'temeo'),\n",
       " ('sempre', 'semre'),\n",
       " ('qual', 'quakl'),\n",
       " ('ela', 'elaá'),\n",
       " ('só', 'síó'),\n",
       " ('utilizar', 'utiqizar'),\n",
       " ('projeto', 'prhojeto'),\n",
       " ('site', 'siàe'),\n",
       " ('sem', 'seém'),\n",
       " ('pelo', 'peln'),\n",
       " ('alura', 'aléra'),\n",
       " ('dia', 'tdia'),\n",
       " ('tudo', 'tuúo'),\n",
       " ('podemos', 'kpodemos'),\n",
       " ('esse', 'eẽsse'),\n",
       " ('já', 'jé'),\n",
       " ('nosso', 'nçosso'),\n",
       " ('são', 'sãô'),\n",
       " ('dos', 'odos'),\n",
       " ('muito', 'tuito'),\n",
       " ('imagem', 'imõgem'),\n",
       " ('sua', 'siua'),\n",
       " ('também', 'tamvbém'),\n",
       " ('ele', 'elpe'),\n",
       " ('fazer', 'façzer'),\n",
       " ('temos', 'teos'),\n",
       " ('essa', 'eũsa'),\n",
       " ('quando', 'quaìdo'),\n",
       " ('vamos', 'vjmos'),\n",
       " ('sobre', 'sxobre'),\n",
       " ('java', 'jkva'),\n",
       " ('das', 'dms'),\n",
       " ('agora', 'agtora'),\n",
       " ('está', 'esútá'),\n",
       " ('cada', 'cava'),\n",
       " ('mesmo', 'medmo'),\n",
       " ('nos', 'ános'),\n",
       " ('forma', 'forûa'),\n",
       " ('seja', 'smeja'),\n",
       " ('então', 'enjtão'),\n",
       " ('criar', 'criôar'),\n",
       " ('código', 'cóàigo'),\n",
       " ('caso', 'èaso'),\n",
       " ('exemplo', 'exbemplo'),\n",
       " ('tem', 'túem'),\n",
       " ('usuário', 'usuárin'),\n",
       " ('dados', 'daáos'),\n",
       " ('python', 'pythoçn'),\n",
       " ('nossa', 'nossk'),\n",
       " ('além', 'âlém'),\n",
       " ('assim', 'aóssim'),\n",
       " ('ter', 'tãer'),\n",
       " ('até', 'vté'),\n",
       " ('bem', 'búm'),\n",
       " ('design', 'íesign'),\n",
       " ('trabalho', 'trabèalho'),\n",
       " ('foi', 'kfoi'),\n",
       " ('apenas', 'aapenas'),\n",
       " ('empresa', 'pmpresa'),\n",
       " ('valor', 'valoqr'),\n",
       " ('será', 'sçerá'),\n",
       " ('entre', 'entró'),\n",
       " ('método', 'nétodo'),\n",
       " ('precisamos', 'prefcisamos'),\n",
       " ('ainda', 'sainda'),\n",
       " ('vai', 'uai'),\n",
       " ('conteúdo', 'cĩonteúdo'),\n",
       " ('seus', 'sâus'),\n",
       " ('eu', 'ìeu'),\n",
       " ('todos', 'todás'),\n",
       " ('tempo', 'utempo'),\n",
       " ('sempre', 'sempce'),\n",
       " ('qual', 'fual'),\n",
       " ('ela', 'elal'),\n",
       " ('só', 'skó'),\n",
       " ('utilizar', 'utilĩzar'),\n",
       " ('projeto', 'proójeto'),\n",
       " ('site', 'isite'),\n",
       " ('sem', 'secm'),\n",
       " ('pelo', 'pẽlo'),\n",
       " ('alura', 'aluéa'),\n",
       " ('dia', 'dil'),\n",
       " ('tudo', 'tudy'),\n",
       " ('ela', 'qelay'),\n",
       " ('só', 'sód'),\n",
       " ('utilizar', 'dtilizacr'),\n",
       " ('projeto', 'bprojõto'),\n",
       " ('site', 'ysiteo'),\n",
       " ('sem', 'sõêm'),\n",
       " ('pelo', 'peàli'),\n",
       " ('alura', 'asuraó'),\n",
       " ('dia', 'deiìa'),\n",
       " ('tudo', 'tuĩdoì'),\n",
       " ('ela', 'eúaa'),\n",
       " ('só', 'ró'),\n",
       " ('utilizar', 'utilizẽaçr'),\n",
       " ('projeto', 'prêjetó'),\n",
       " ('site', 'sqiqte'),\n",
       " ('sem', 'sũexm'),\n",
       " ('pelo', 'pçlxo'),\n",
       " ('alura', 'uluraa'),\n",
       " ('dia', 'dĩaz'),\n",
       " ('tudo', 'kzudo'),\n",
       " ('corretor', 'correptor'),\n",
       " ('tática', 'trtica'),\n",
       " ('empoderamento', 'ewpoderamento'),\n",
       " ('linux', 'lifux'),\n",
       " ('cachorro', 'cachoçro'),\n",
       " ('gato', 'îgato'),\n",
       " ('cavalo', 'cakvalo'),\n",
       " ('relógio', 'relógiuo'),\n",
       " ('canela', 'canelac'),\n",
       " ('tênis', 'tênisy'),\n",
       " ('ansiosa', 'anciosa'),\n",
       " ('ansiosa', 'ancciosa'),\n",
       " ('ansiosa', 'ansioa'),\n",
       " ('empoderamento', 'empoderamento'),\n",
       " ('asterisco', 'asterístico'),\n",
       " ('gratuito', 'gratuíto'),\n",
       " ('entretido', 'entertido'),\n",
       " ('ritmo', 'ritimo'),\n",
       " ('idiota', 'indiota'),\n",
       " ('tomara', 'tomare'),\n",
       " ('seja', 'seje'),\n",
       " ('prevalecer', 'provalecer'),\n",
       " ('esteja', 'esteje'),\n",
       " ('mendigo', 'mindigo'),\n",
       " ('cérebro', 'célebro'),\n",
       " ('perturbar', 'pertubar')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, \"r\", encoding = \"utf-8\")\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste\n",
    "    \n",
    "lista_teste = cria_dados_teste(\"palavras.txt\")\n",
    "lista_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "527a62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08% de 186 palavras\n"
     ]
    }
   ],
   "source": [
    "def avaliador (testes):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras\")\n",
    "\n",
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f68334d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85392421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alóigica', 'blóigica', 'clóigica', 'dlóigica', 'elóigica', 'flóigica', 'glóigica', 'hlóigica', 'ilóigica', 'jlóigica', 'klóigica', 'llóigica', 'mlóigica', 'nlóigica', 'olóigica', 'plóigica', 'qlóigica', 'rlóigica', 'slóigica', 'tlóigica', 'ulóigica', 'vlóigica', 'wlóigica', 'xlóigica', 'ylóigica', 'zlóigica', 'àlóigica', 'álóigica', 'âlóigica', 'ãlóigica', 'èlóigica', 'élóigica', 'êlóigica', 'ìlóigica', 'ílóigica', 'îlóigica', 'òlóigica', 'ólóigica', 'ôlóigica', 'õlóigica', 'ùlóigica', 'úlóigica', 'ûlóigica', 'çlóigica', 'laóigica', 'lbóigica', 'lcóigica', 'ldóigica', 'leóigica', 'lfóigica', 'lgóigica', 'lhóigica', 'lióigica', 'ljóigica', 'lkóigica', 'llóigica', 'lmóigica', 'lnóigica', 'loóigica', 'lpóigica', 'lqóigica', 'lróigica', 'lsóigica', 'ltóigica', 'luóigica', 'lvóigica', 'lwóigica', 'lxóigica', 'lyóigica', 'lzóigica', 'làóigica', 'láóigica', 'lâóigica', 'lãóigica', 'lèóigica', 'léóigica', 'lêóigica', 'lìóigica', 'líóigica', 'lîóigica', 'lòóigica', 'lóóigica', 'lôóigica', 'lõóigica', 'lùóigica', 'lúóigica', 'lûóigica', 'lçóigica', 'lóaigica', 'lóbigica', 'lócigica', 'lódigica', 'lóeigica', 'lófigica', 'lógigica', 'lóhigica', 'lóiigica', 'lójigica', 'lókigica', 'lóligica', 'lómigica', 'lónigica', 'lóoigica', 'lópigica', 'lóqigica', 'lórigica', 'lósigica', 'lótigica', 'lóuigica', 'lóvigica', 'lówigica', 'lóxigica', 'lóyigica', 'lózigica', 'lóàigica', 'lóáigica', 'lóâigica', 'lóãigica', 'lóèigica', 'lóéigica', 'lóêigica', 'lóìigica', 'lóíigica', 'lóîigica', 'lóòigica', 'lóóigica', 'lóôigica', 'lóõigica', 'lóùigica', 'lóúigica', 'lóûigica', 'lóçigica', 'lóiagica', 'lóibgica', 'lóicgica', 'lóidgica', 'lóiegica', 'lóifgica', 'lóiggica', 'lóihgica', 'lóiigica', 'lóijgica', 'lóikgica', 'lóilgica', 'lóimgica', 'lóingica', 'lóiogica', 'lóipgica', 'lóiqgica', 'lóirgica', 'lóisgica', 'lóitgica', 'lóiugica', 'lóivgica', 'lóiwgica', 'lóixgica', 'lóiygica', 'lóizgica', 'lóiàgica', 'lóiágica', 'lóiâgica', 'lóiãgica', 'lóiègica', 'lóiégica', 'lóiêgica', 'lóiìgica', 'lóiígica', 'lóiîgica', 'lóiògica', 'lóiógica', 'lóiôgica', 'lóiõgica', 'lóiùgica', 'lóiúgica', 'lóiûgica', 'lóiçgica', 'lóigaica', 'lóigbica', 'lóigcica', 'lóigdica', 'lóigeica', 'lóigfica', 'lóiggica', 'lóighica', 'lóigiica', 'lóigjica', 'lóigkica', 'lóiglica', 'lóigmica', 'lóignica', 'lóigoica', 'lóigpica', 'lóigqica', 'lóigrica', 'lóigsica', 'lóigtica', 'lóiguica', 'lóigvica', 'lóigwica', 'lóigxica', 'lóigyica', 'lóigzica', 'lóigàica', 'lóigáica', 'lóigâica', 'lóigãica', 'lóigèica', 'lóigéica', 'lóigêica', 'lóigìica', 'lóigíica', 'lóigîica', 'lóigòica', 'lóigóica', 'lóigôica', 'lóigõica', 'lóigùica', 'lóigúica', 'lóigûica', 'lóigçica', 'lóigiaca', 'lóigibca', 'lóigicca', 'lóigidca', 'lóigieca', 'lóigifca', 'lóigigca', 'lóigihca', 'lóigiica', 'lóigijca', 'lóigikca', 'lóigilca', 'lóigimca', 'lóiginca', 'lóigioca', 'lóigipca', 'lóigiqca', 'lóigirca', 'lóigisca', 'lóigitca', 'lóigiuca', 'lóigivca', 'lóigiwca', 'lóigixca', 'lóigiyca', 'lóigizca', 'lóigiàca', 'lóigiáca', 'lóigiâca', 'lóigiãca', 'lóigièca', 'lóigiéca', 'lóigiêca', 'lóigiìca', 'lóigiíca', 'lóigiîca', 'lóigiòca', 'lóigióca', 'lóigiôca', 'lóigiõca', 'lóigiùca', 'lóigiúca', 'lóigiûca', 'lóigiçca', 'lóigicaa', 'lóigicba', 'lóigicca', 'lóigicda', 'lóigicea', 'lóigicfa', 'lóigicga', 'lóigicha', 'lóigicia', 'lóigicja', 'lóigicka', 'lóigicla', 'lóigicma', 'lóigicna', 'lóigicoa', 'lóigicpa', 'lóigicqa', 'lóigicra', 'lóigicsa', 'lóigicta', 'lóigicua', 'lóigicva', 'lóigicwa', 'lóigicxa', 'lóigicya', 'lóigicza', 'lóigicàa', 'lóigicáa', 'lóigicâa', 'lóigicãa', 'lóigicèa', 'lóigicéa', 'lóigicêa', 'lóigicìa', 'lóigicía', 'lóigicîa', 'lóigicòa', 'lóigicóa', 'lóigicôa', 'lóigicõa', 'lóigicùa', 'lóigicúa', 'lóigicûa', 'lóigicça', 'lóigicaa', 'lóigicab', 'lóigicac', 'lóigicad', 'lóigicae', 'lóigicaf', 'lóigicag', 'lóigicah', 'lóigicai', 'lóigicaj', 'lóigicak', 'lóigical', 'lóigicam', 'lóigican', 'lóigicao', 'lóigicap', 'lóigicaq', 'lóigicar', 'lóigicas', 'lóigicat', 'lóigicau', 'lóigicav', 'lóigicaw', 'lóigicax', 'lóigicay', 'lóigicaz', 'lóigicaà', 'lóigicaá', 'lóigicaâ', 'lóigicaã', 'lóigicaè', 'lóigicaé', 'lóigicaê', 'lóigicaì', 'lóigicaí', 'lóigicaî', 'lóigicaò', 'lóigicaó', 'lóigicaô', 'lóigicaõ', 'lóigicaù', 'lóigicaú', 'lóigicaû', 'lóigicaç', 'óigica', 'ligica', 'lógica', 'lóiica', 'lóigca', 'lóigia', 'lóigic', 'lóigica']\n"
     ]
    }
   ],
   "source": [
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavra_exemplo = \"lóigica\"\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59cca02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.4% de 186 palavras\n"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed6a8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáàãâéèêíìóòõôúùûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc688d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algóica', 'blgóica', 'clgóica', 'dlgóica', 'elgóica', 'flgóica', 'glgóica', 'hlgóica', 'ilgóica', 'jlgóica', 'klgóica', 'llgóica', 'mlgóica', 'nlgóica', 'olgóica', 'plgóica', 'qlgóica', 'rlgóica', 'slgóica', 'tlgóica', 'ulgóica', 'vlgóica', 'wlgóica', 'xlgóica', 'ylgóica', 'zlgóica', 'àlgóica', 'álgóica', 'âlgóica', 'ãlgóica', 'èlgóica', 'élgóica', 'êlgóica', 'ìlgóica', 'ílgóica', 'îlgóica', 'òlgóica', 'ólgóica', 'ôlgóica', 'õlgóica', 'ùlgóica', 'úlgóica', 'ûlgóica', 'çlgóica', 'lagóica', 'lbgóica', 'lcgóica', 'ldgóica', 'legóica', 'lfgóica', 'lggóica', 'lhgóica', 'ligóica', 'ljgóica', 'lkgóica', 'llgóica', 'lmgóica', 'lngóica', 'logóica', 'lpgóica', 'lqgóica', 'lrgóica', 'lsgóica', 'ltgóica', 'lugóica', 'lvgóica', 'lwgóica', 'lxgóica', 'lygóica', 'lzgóica', 'làgóica', 'lágóica', 'lâgóica', 'lãgóica', 'lègóica', 'légóica', 'lêgóica', 'lìgóica', 'lígóica', 'lîgóica', 'lògóica', 'lógóica', 'lôgóica', 'lõgóica', 'lùgóica', 'lúgóica', 'lûgóica', 'lçgóica', 'lgaóica', 'lgbóica', 'lgcóica', 'lgdóica', 'lgeóica', 'lgfóica', 'lggóica', 'lghóica', 'lgióica', 'lgjóica', 'lgkóica', 'lglóica', 'lgmóica', 'lgnóica', 'lgoóica', 'lgpóica', 'lgqóica', 'lgróica', 'lgsóica', 'lgtóica', 'lguóica', 'lgvóica', 'lgwóica', 'lgxóica', 'lgyóica', 'lgzóica', 'lgàóica', 'lgáóica', 'lgâóica', 'lgãóica', 'lgèóica', 'lgéóica', 'lgêóica', 'lgìóica', 'lgíóica', 'lgîóica', 'lgòóica', 'lgóóica', 'lgôóica', 'lgõóica', 'lgùóica', 'lgúóica', 'lgûóica', 'lgçóica', 'lgóaica', 'lgóbica', 'lgócica', 'lgódica', 'lgóeica', 'lgófica', 'lgógica', 'lgóhica', 'lgóiica', 'lgójica', 'lgókica', 'lgólica', 'lgómica', 'lgónica', 'lgóoica', 'lgópica', 'lgóqica', 'lgórica', 'lgósica', 'lgótica', 'lgóuica', 'lgóvica', 'lgówica', 'lgóxica', 'lgóyica', 'lgózica', 'lgóàica', 'lgóáica', 'lgóâica', 'lgóãica', 'lgóèica', 'lgóéica', 'lgóêica', 'lgóìica', 'lgóíica', 'lgóîica', 'lgóòica', 'lgóóica', 'lgóôica', 'lgóõica', 'lgóùica', 'lgóúica', 'lgóûica', 'lgóçica', 'lgóiaca', 'lgóibca', 'lgóicca', 'lgóidca', 'lgóieca', 'lgóifca', 'lgóigca', 'lgóihca', 'lgóiica', 'lgóijca', 'lgóikca', 'lgóilca', 'lgóimca', 'lgóinca', 'lgóioca', 'lgóipca', 'lgóiqca', 'lgóirca', 'lgóisca', 'lgóitca', 'lgóiuca', 'lgóivca', 'lgóiwca', 'lgóixca', 'lgóiyca', 'lgóizca', 'lgóiàca', 'lgóiáca', 'lgóiâca', 'lgóiãca', 'lgóièca', 'lgóiéca', 'lgóiêca', 'lgóiìca', 'lgóiíca', 'lgóiîca', 'lgóiòca', 'lgóióca', 'lgóiôca', 'lgóiõca', 'lgóiùca', 'lgóiúca', 'lgóiûca', 'lgóiçca', 'lgóicaa', 'lgóicba', 'lgóicca', 'lgóicda', 'lgóicea', 'lgóicfa', 'lgóicga', 'lgóicha', 'lgóicia', 'lgóicja', 'lgóicka', 'lgóicla', 'lgóicma', 'lgóicna', 'lgóicoa', 'lgóicpa', 'lgóicqa', 'lgóicra', 'lgóicsa', 'lgóicta', 'lgóicua', 'lgóicva', 'lgóicwa', 'lgóicxa', 'lgóicya', 'lgóicza', 'lgóicàa', 'lgóicáa', 'lgóicâa', 'lgóicãa', 'lgóicèa', 'lgóicéa', 'lgóicêa', 'lgóicìa', 'lgóicía', 'lgóicîa', 'lgóicòa', 'lgóicóa', 'lgóicôa', 'lgóicõa', 'lgóicùa', 'lgóicúa', 'lgóicûa', 'lgóicça', 'lgóicaa', 'lgóicab', 'lgóicac', 'lgóicad', 'lgóicae', 'lgóicaf', 'lgóicag', 'lgóicah', 'lgóicai', 'lgóicaj', 'lgóicak', 'lgóical', 'lgóicam', 'lgóican', 'lgóicao', 'lgóicap', 'lgóicaq', 'lgóicar', 'lgóicas', 'lgóicat', 'lgóicau', 'lgóicav', 'lgóicaw', 'lgóicax', 'lgóicay', 'lgóicaz', 'lgóicaà', 'lgóicaá', 'lgóicaâ', 'lgóicaã', 'lgóicaè', 'lgóicaé', 'lgóicaê', 'lgóicaì', 'lgóicaí', 'lgóicaî', 'lgóicaò', 'lgóicaó', 'lgóicaô', 'lgóicaõ', 'lgóicaù', 'lgóicaú', 'lgóicaû', 'lgóicaç', 'góica', 'lóica', 'lgica', 'lgóca', 'lgóia', 'lgóic', 'lgóica', 'agóica', 'bgóica', 'cgóica', 'dgóica', 'egóica', 'fgóica', 'ggóica', 'hgóica', 'igóica', 'jgóica', 'kgóica', 'lgóica', 'mgóica', 'ngóica', 'ogóica', 'pgóica', 'qgóica', 'rgóica', 'sgóica', 'tgóica', 'ugóica', 'vgóica', 'wgóica', 'xgóica', 'ygóica', 'zgóica', 'ágóica', 'àgóica', 'ãgóica', 'âgóica', 'égóica', 'ègóica', 'êgóica', 'ígóica', 'ìgóica', 'ógóica', 'ògóica', 'õgóica', 'ôgóica', 'úgóica', 'ùgóica', 'ûgóica', 'çgóica', 'laóica', 'lbóica', 'lcóica', 'ldóica', 'leóica', 'lfóica', 'lgóica', 'lhóica', 'lióica', 'ljóica', 'lkóica', 'llóica', 'lmóica', 'lnóica', 'loóica', 'lpóica', 'lqóica', 'lróica', 'lsóica', 'ltóica', 'luóica', 'lvóica', 'lwóica', 'lxóica', 'lyóica', 'lzóica', 'láóica', 'làóica', 'lãóica', 'lâóica', 'léóica', 'lèóica', 'lêóica', 'líóica', 'lìóica', 'lóóica', 'lòóica', 'lõóica', 'lôóica', 'lúóica', 'lùóica', 'lûóica', 'lçóica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgáica', 'lgàica', 'lgãica', 'lgâica', 'lgéica', 'lgèica', 'lgêica', 'lgíica', 'lgìica', 'lgóica', 'lgòica', 'lgõica', 'lgôica', 'lgúica', 'lgùica', 'lgûica', 'lgçica', 'lgóaca', 'lgóbca', 'lgócca', 'lgódca', 'lgóeca', 'lgófca', 'lgógca', 'lgóhca', 'lgóica', 'lgójca', 'lgókca', 'lgólca', 'lgómca', 'lgónca', 'lgóoca', 'lgópca', 'lgóqca', 'lgórca', 'lgósca', 'lgótca', 'lgóuca', 'lgóvca', 'lgówca', 'lgóxca', 'lgóyca', 'lgózca', 'lgóáca', 'lgóàca', 'lgóãca', 'lgóâca', 'lgóéca', 'lgóèca', 'lgóêca', 'lgóíca', 'lgóìca', 'lgóóca', 'lgóòca', 'lgóõca', 'lgóôca', 'lgóúca', 'lgóùca', 'lgóûca', 'lgóçca', 'lgóiaa', 'lgóiba', 'lgóica', 'lgóida', 'lgóiea', 'lgóifa', 'lgóiga', 'lgóiha', 'lgóiia', 'lgóija', 'lgóika', 'lgóila', 'lgóima', 'lgóina', 'lgóioa', 'lgóipa', 'lgóiqa', 'lgóira', 'lgóisa', 'lgóita', 'lgóiua', 'lgóiva', 'lgóiwa', 'lgóixa', 'lgóiya', 'lgóiza', 'lgóiáa', 'lgóiàa', 'lgóiãa', 'lgóiâa', 'lgóiéa', 'lgóièa', 'lgóiêa', 'lgóiía', 'lgóiìa', 'lgóióa', 'lgóiòa', 'lgóiõa', 'lgóiôa', 'lgóiúa', 'lgóiùa', 'lgóiûa', 'lgóiça', 'lgóica', 'lgóicb', 'lgóicc', 'lgóicd', 'lgóice', 'lgóicf', 'lgóicg', 'lgóich', 'lgóici', 'lgóicj', 'lgóick', 'lgóicl', 'lgóicm', 'lgóicn', 'lgóico', 'lgóicp', 'lgóicq', 'lgóicr', 'lgóics', 'lgóict', 'lgóicu', 'lgóicv', 'lgóicw', 'lgóicx', 'lgóicy', 'lgóicz', 'lgóicá', 'lgóicà', 'lgóicã', 'lgóicâ', 'lgóicé', 'lgóicè', 'lgóicê', 'lgóicí', 'lgóicì', 'lgóicó', 'lgóicò', 'lgóicõ', 'lgóicô', 'lgóicú', 'lgóicù', 'lgóicû', 'lgóicç', 'lgóicaa', 'lgóicab', 'lgóicac', 'lgóicad', 'lgóicae', 'lgóicaf', 'lgóicag', 'lgóicah', 'lgóicai', 'lgóicaj', 'lgóicak', 'lgóical', 'lgóicam', 'lgóican', 'lgóicao', 'lgóicap', 'lgóicaq', 'lgóicar', 'lgóicas', 'lgóicat', 'lgóicau', 'lgóicav', 'lgóicaw', 'lgóicax', 'lgóicay', 'lgóicaz', 'lgóicaá', 'lgóicaà', 'lgóicaã', 'lgóicaâ', 'lgóicaé', 'lgóicaè', 'lgóicaê', 'lgóicaí', 'lgóicaì', 'lgóicaó', 'lgóicaò', 'lgóicaõ', 'lgóicaô', 'lgóicaú', 'lgóicaù', 'lgóicaû', 'lgóicaç', 'glóica', 'lógica', 'lgióca', 'lgócia', 'lgóiac']\n"
     ]
    }
   ],
   "source": [
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáàãâéèêíìóòõôúùûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def inverte_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "    palavras_geradas += inverte_letra(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavra_exemplo = \"lgóica\"\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b312a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34% de 186 palavras\n"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5943553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34% de 186 palavras, desconhecidas é 6.99%\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "        else:\n",
    "            desconhecida += (correta not in vocabulario)\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras, desconhecidas é {taxa_desconhecida}%\")\n",
    "\n",
    "\n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c5ff1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavra = \"lóiigica\"\n",
    "\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "palavras_g = gerador_turbinado(gerador_palavras(palavra))\n",
    "\"lógica\" in palavras_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b76641ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676760"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palavras_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6afb9126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def novo_corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    palavra_correta = max(candidatos, key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "novo_corretor(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7098bbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.38% de 186 palavras, desconhecidas 6.99%\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = novo_corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras, desconhecidas {taxa_desconhecida}%\")\n",
    "\n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1bd3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esje-esse-se\n",
      "sãêo-são-não\n",
      "dosa-dos-do\n",
      "eme-em-de\n",
      "eàssa-essa-esse\n",
      "daõs-das-da\n",
      "céda-cada-da\n",
      "noâ-no-o\n",
      "enêão-então-não\n",
      "tĩem-tem-em\n",
      "nossah-nossa-nosso\n",
      "teb-tem-de\n",
      "atĩ-até-a\n",
      "âem-em-de\n",
      "foo-foi-o\n",
      "serr-ser-se\n",
      "entke-entre-então\n",
      "van-vai-a\n",
      "çeus-seus-seu\n",
      "eû-e-de\n",
      "temeo-tempo-temos\n",
      "semre-sempre-ser\n",
      "elaá-ela-ele\n",
      "síó-só-se\n",
      "siàe-site-se\n",
      "seém-sem-em\n",
      "peln-pelo-ele\n",
      "aléra-alura-agora\n",
      "tdia-dia-da\n",
      "tuúo-tudo-tipo\n",
      "jé-é-de\n",
      "sãô-são-não\n",
      "odos-dos-do\n",
      "siua-sua-seu\n",
      "elpe-ele-esse\n",
      "teos-temos-os\n",
      "eũsa-essa-esse\n",
      "vjmos-vamos-temos\n",
      "dms-dos-de\n",
      "cava-java-para\n",
      "ános-nos-no\n",
      "èaso-caso-as\n",
      "túem-tem-em\n",
      "daáos-dados-dos\n",
      "nossk-nosso-nosso\n",
      "tãer-ter-ser\n",
      "vté-até-é\n",
      "búm-bem-um\n",
      "sçerá-será-ser\n",
      "entró-entre-então\n",
      "uai-vai-a\n",
      "sâus-seus-seu\n",
      "ìeu-seu-de\n",
      "fual-qual-sua\n",
      "elal-ela-ele\n",
      "skó-só-se\n",
      "secm-sem-em\n",
      "aluéa-alura-além\n",
      "dil-dia-de\n",
      "sód-só-se\n",
      "eúaa-aeúaa-essa\n",
      "ró-só-de\n",
      "dĩaz-adĩaz-da\n",
      "correptor-corretor-correto\n",
      "trtica-tática-prática\n",
      "ewpoderamento-aewpoderamento-ewpoderamento\n",
      "îgato-gato-fato\n",
      "cakvalo-acakvalo-carvalho\n",
      "canelac-acanelac-janela\n",
      "tênisy-atênisy-tênisy\n",
      "anciosa-aanciosa-ansioso\n",
      "ancciosa-aancciosa-ancciosa\n",
      "ansioa-aansioa-antiga\n",
      "asterístico-aasterístico-asterístico\n",
      "entertido-aentertido-entendido\n",
      "ritimo-ritmo-ótimo\n",
      "indiota-aindiota-indica\n",
      "tomare-tomar-tomar\n",
      "seje-seja-se\n",
      "provalecer-aprovalecer-prevaleceu\n",
      "esteje-esteja-este\n",
      "mindigo-amindigo-indico\n",
      "pertubar-apertubar-derrubar\n",
      "55.38% de 186 palavras, desconhecidas 6.99%\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = novo_corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "        else:\n",
    "            print(errada + \"-\" + corretor(errada) + \"-\" + palavra_corrigida)\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras, desconhecidas {taxa_desconhecida}%\")\n",
    "\n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0654704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34% de 186 palavras, desconhecidas 6.99%\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras, desconhecidas {taxa_desconhecida}%\")\n",
    "\n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "502cc0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fica\n",
      "lógica\n"
     ]
    }
   ],
   "source": [
    "palavra = \"lgica\"\n",
    "print(novo_corretor(palavra))\n",
    "print(corretor(palavra))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
